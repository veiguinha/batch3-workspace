{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dc148b069032ac72",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# SLU16 - Data Sufficiency and Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-73d0f28288cec5d9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot as plt\n",
    "from hashlib import sha1 # just for grading purposes\n",
    "import json # just for grading purposes\n",
    "\n",
    "def _hash(obj):\n",
    "    if type(obj) is not str:\n",
    "        obj = json.dumps(obj)\n",
    "    return sha1(obj.encode()).hexdigest()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e47d27916830bf56",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# load up a classification dataset\n",
    "\n",
    "X = pd.read_csv('data/exercise_X.csv')\n",
    "y = pd.read_csv('data/exercise_y.csv')['label']\n",
    "# give X a quick look\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a7ff45300c5ff1f4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# looks like a balanced binary target\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bd5e4f00e0c6d410",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Find the first obviously useless feature\n",
    "\n",
    "Can you determine which of the features contains all uniques and therefore cannot have any predictive power?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to determine which of the features serves as a categorical\n",
    "# feature and contains all uniques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a584b7a530c36ed0",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# set the variable feature_all_unique to the name of the feature\n",
    "# that contains all uniques\n",
    "feature_all_unique = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-805f4867b353fe96",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN TESTS\n",
    "assert _hash(feature_all_unique) == '87ea5dfc8b8e384d848979496e706390b497e547'\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-602ec15412879335",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Find the second obviously useless feature\n",
    "\n",
    "This one doesn't contain all uniques but based upon some Single Factor Analysis you should be able to determine which feature isn't worth\n",
    "bothering with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell to do some more SFA on other features to determine\n",
    "# which of them is useless\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f99bab2575793069",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Use this cell to determine the other obviously useless feature\n",
    "other_useless_feature = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-6964c9cd17f443b8",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN TESTS\n",
    "assert _hash(other_useless_feature) == '04c03b252faf210d252b1d80590911758427b048'\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-949c10443e311151",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# now drop the features that you determined to be useless and store them in X_1\n",
    "\n",
    "# X_1 = X.drop(...)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-476d75f82723fb0c",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN TESTS\n",
    "assert _hash(list(sorted(X_1.columns))) == '7c9a6ed68a038fdcf0722571cbc6a60ed958d19b'\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d29f316d3f5c61e1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Find the rest of the useless features\n",
    "\n",
    "Single Factor Analysis isn't likely to do much in helping us to determine\n",
    "which of the rest of the features are useless. We'll need to some `feature_importances` in order to find the rest of these bad boys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6fbdfd50396e632f",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Now let's import and train the classifier and get the feature importance using\n",
    "# the X_1 DataFrame\n",
    "\n",
    "# First import a tree based classifier\n",
    "\n",
    "# from sklearn... import ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Create your classifier, assign it to the clf variable and then\n",
    "# train it on X_1 and y\n",
    "clf = None\n",
    "\n",
    "# once the classifier is trained, set the feature importances here\n",
    "# make it a pandas series with the index being the column names\n",
    "# so that we can visualize the results\n",
    "feature_importances = None\n",
    "\n",
    "# set the random_state=1 and max_depth=5 or the tests won't pass!\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-ca84ae67d444979f",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN TESTS\n",
    "assert hasattr(clf, 'feature_importances_'), 'The classifier must be a tree based classifier'\n",
    "assert clf.random_state == 1, 'random_state must be 1'\n",
    "assert clf.max_depth == 5, 'max_depth must be 5'\n",
    "assert np.isclose(feature_importances['feature_0'], 0.031820, atol=1e-5), 'feature 0 importance seems off'\n",
    "assert np.isclose(feature_importances['feature_1'], 0.128733, atol=1e-5), 'feature 1 importance seems off'\n",
    "assert np.isclose(feature_importances['feature_6'], 0.146977, atol=1e-5), 'feature 6 importance seems off'\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-662fccd5e1566e6a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "feature_importances.plot.barh();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d91aeb204b6b8280",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Now let's import and train the classifier and get the feature importance using\n",
    "# the X_1 DataFrame\n",
    "\n",
    "# First import a LogisticRegression\n",
    "\n",
    "# from sklearn... import ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Create your classifier, assign it to the clf variable and then\n",
    "# train it on X_1 and y\n",
    "clf = None\n",
    "\n",
    "# once the classifier is trained, set the coefs_ here\n",
    "# make it a pandas series with the index being the column names\n",
    "# so that we can visualize the results\n",
    "# BE SURE to take the absolute value of the coefs\n",
    "abs_coefs = None\n",
    "\n",
    "# set the solver='lbfgs' and random_state=1 or the tests won't pass!\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-21604081b6abb0ef",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN TESTS\n",
    "assert isinstance(clf, LogisticRegression), 'The classifier must be a logistic regression'\n",
    "assert clf.random_state == 1, 'random_state must be 1'\n",
    "assert clf.solver == 'lbfgs', 'solver must be lbfgs'\n",
    "assert np.isclose(abs_coefs['feature_0'], 0.031889, atol=1e-5), 'feature 0 coef seems off'\n",
    "assert np.isclose(abs_coefs['feature_1'], 0.093313, atol=1e-5), 'feature 1 coef seems off'\n",
    "assert np.isclose(abs_coefs['feature_6'], 0.405876, atol=1e-5), 'feature 6 coef seems off'\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3b4524fd9720e964",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "abs_coefs.plot.barh();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0dc20755ad6d11ce",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# now remove the 3 remaining useless features and store them in\n",
    "# the variable X_2\n",
    "\n",
    "# X_2 = X_1.drop(...)\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-47bb1f540f749a88",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN TESTS\n",
    "assert _hash(list(sorted(X_2.columns))) == '0ba088ebdcf2b8598c95a2a89cf140b86ec1d6d5'\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bd25a293de8f844d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Correlations\n",
    "\n",
    "Determine the correlations between each of the features and the target column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-67f849ea5722ac92",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv('data/exercise_X.csv')\n",
    "y = pd.read_csv('data/exercise_y.csv')['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-343f6f6aefebbb4e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# In this cell, compute the absolute value of the correlations between each feature and the target and store it in\n",
    "# a variable called abs_corrs\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-83e620d736ca893b",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN TESTS\n",
    "expected_features = {\n",
    "    'feature_0', \n",
    "    'feature_1', \n",
    "    'feature_2', \n",
    "    'feature_3', \n",
    "    'feature_4',\n",
    "    'feature_5',\n",
    "    'feature_6',\n",
    "    'feature_7',\n",
    "}\n",
    "assert set(abs_corrs.index) == expected_features, 'you should only have expected_features features'\n",
    "assert np.isclose(abs_corrs['feature_0'], 0.027928, rtol=1e-04)\n",
    "assert np.isclose(abs_corrs['feature_5'], 0.008327, rtol=1e-04)\n",
    "assert np.isclose(abs_corrs['feature_7'], 0.285048, rtol=1e-04)\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-168fac9d07e35232",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# The learning curve\n",
    "\n",
    "Okay now that we have gotten rid of all those useless features, let's focus on getting a sense for how much data we need in order to have\n",
    "reasonable performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f22e3c91b478ba32",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Now create a dataframe that has a single feature that is the\n",
    "# cross validation score in order to help us understand\n",
    "# how increasing amounts of data affect the performance\n",
    "\n",
    "# HINT: just use the snippet from the Learning Notebook\n",
    "train_scores_mean = None\n",
    "test_scores_mean = None\n",
    "\n",
    "# instantiate a classifier that you will inspect the learning rate of\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth=5, random_state=1)\n",
    "\n",
    "# IMPORTANT: Be sure to train on X_2\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-d1bded5a2e391786",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN TESTS\n",
    "# round in order to compensate for implementation details\n",
    "\n",
    "assert math.isclose(sum(train_scores_mean), 4.5, rel_tol=1e-2)\n",
    "assert math.isclose(sum(test_scores_mean), 3.8, rel_tol=1e-2)\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b91ef37925959db9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "learning_curve_df = pd.DataFrame({\n",
    "    'Training Scores': train_scores_mean,\n",
    "    'Test Set scores': test_scores_mean\n",
    "}, index=train_sizes)\n",
    "\n",
    "learning_curve_df.plot.line(\n",
    "    title='Decision Tree Learning Curve'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fc4e8393bc289ff2",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Now select the minimum training set size that this particular classifier\n",
    "# seems to need before it's learning rate stabilizes\n",
    "\n",
    "min_train_set_size = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1669e239252c8492",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN TESTS\n",
    "assert _hash(min_train_set_size) == 'ba30fd97b4127db56e9f4d3d9c030d71646fd2e7'\n",
    "### END TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
