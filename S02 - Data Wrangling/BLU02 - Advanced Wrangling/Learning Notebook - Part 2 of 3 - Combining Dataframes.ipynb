{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLU02 - Learning Notebook - Data wrangling workflows - Part 2 of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Combining dataframes in Pandas\n",
    "\n",
    "## 2.1 How many programs are there per season?\n",
    "\n",
    "How many different programs does the NYP typically present per season?\n",
    "\n",
    "Programs are under `/data/programs/` which contains a file per Season.\n",
    "\n",
    "### Concatenate\n",
    "\n",
    "To analyze how many programs there are per season, over time, we need a single dataframe containing *all* seasons.\n",
    "\n",
    "Concatenation means, in short, to unite multiple dataframes (or series) in one. \n",
    "\n",
    "The `pd.concat()` function performs concatenation operations along an axis (`axis=0` for index and `axis=1` for columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_0 = pd.read_csv('./data/programs/1842-43.csv')\n",
    "season_1 = pd.read_csv('./data/programs/1843-44.csv')\n",
    "\n",
    "seasons = [season_0, season_1]\n",
    "pd.concat(seasons, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating like this makes no sense, as we no longer have a single observation per row.\n",
    "\n",
    "What we want to do instead is to concatenate the dataframe along the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(seasons, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataframe looks better, but there's something weird with the index: it's not unique anymore.\n",
    "\n",
    "Different observations share the same index. Not cool.\n",
    "\n",
    "For dataframes that don't have a meaningful index, you may wish to ignore the indexes altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(seasons, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try something different. \n",
    "\n",
    "Let's try to change the name of the columns, so that each dataframe has different ones, before concatenating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_0_ = season_0.copy()\n",
    "season_0_.columns = [0, 1, 2, 'Season']\n",
    "seasons_ = [season_0_, season_1]\n",
    "pd.concat(seasons_, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What a mess! What did we learn?\n",
    "\n",
    "* When the dataframes have different columns, `pd.concat()` will take the union of all dataframes by default (no information loss)\n",
    "* Concatenation will fill columns that are not present for specific dataframes with `np.NaN` (missing values).\n",
    "\n",
    "The good news is that you can set how you want to glue the dataframes in regards to the other axis, the one not being concatenated. \n",
    "\n",
    "Setting `join='inner'` will take the intersection, i.e., the columns that are present in all dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(seasons_, axis=0, join='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There you go. Concatenation complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append\n",
    "\n",
    "The method `df.append()` is a shortcut for `pd.concat()`, that can be called on either a `pd.DataFrame` or a `pd.Series`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_0.append(season_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can take multiple objects to concatenate as well. Please note the `ignore_index=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_2 = pd.read_csv('./data/programs/1844-45.csv')\n",
    "\n",
    "more_seasons = [season_1, season_2]\n",
    "season_0.append(more_seasons, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are good to go. Let's use `pd.concat` to combine all seasons into a great dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_season(file):\n",
    "    path = os.path.join('.', 'data', 'programs', file)\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "files = os.listdir('./data/programs/')\n",
    "files = [f for f in files if '.csv' in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A logical approach would be to iterate over all files and appending all of them to a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "programs = pd.DataFrame()\n",
    "for file in files:\n",
    "    season = read_season(file)\n",
    "    programs = programs.append(season, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth noting that both `pd.concat()` and `df.append()` make a full copy of the data and continually reusing this function can create a significant performance hit. \n",
    "\n",
    "Instead, use a list comprehension if you need to use the operation several times. \n",
    "\n",
    "This way, you only call `pd.concat()` or `df.append()` once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "seasons = [read_season(f) for f in files if '.csv' in f]\n",
    "programs = pd.concat(seasons, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = [read_season(f) for f in files if '.csv' in f]\n",
    "programs = pd.concat(seasons, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the final `programs` dataframe, we can see how the number of distinct programs changes over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "programs['Season'] = pd.to_datetime(programs['Season'].str[:4])\n",
    "\n",
    "(programs.groupby('Season')\n",
    "         .size()\n",
    "         .plot(legend=False, use_index=True, figsize=(10, 7),\n",
    "               title='Number of programs per season (from 1842-43 to 2016-17)'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NYP appears to be investing in increasing the number of distinct programs per season since '95. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 How many concerts are there per season?\n",
    "\n",
    "What about the number of concerts? The first thing we need to do is to import the `concerts.csv` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concerts = pd.read_csv('./data/concerts.csv')\n",
    "concerts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the Leon Levy Digital Archives ID (`GUID`) to identify each program.\n",
    "\n",
    "Now, we have information regarding all the concerts that took place and the season for each program.\n",
    "\n",
    "The problem? Information about the concert and the season are in different tables, and the program is the glue between the two. Familiar?\n",
    "\n",
    "### Merge\n",
    "\n",
    "Pandas provides high-performance join operations, very similar to SQL.\n",
    "\n",
    "The method `df.merge()` method provides an interface for all database-like join methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?pd.merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call `pd.merge` to join both tables on the `GUID` (and the `ProgramID`, that provides similar info)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since GUID and ProgramID offer similar info, we will drop the later.\n",
    "programs = programs.drop(columns='ProgramID')\n",
    "\n",
    "df = pd.merge(programs, concerts, on='GUID')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, alternatively, we can call `merge()` directly on the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = programs.merge(concerts, on='GUID')\n",
    "df_.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The critical parameter here is the `how`. Since we are not explicitly using it, the merge default to `inner` (for inner-join) by default.\n",
    "\n",
    "But, in fact, you can use any join, just like you did in SQL: `left`, `right`, `outer` and `inner`.\n",
    "\n",
    "Remember?\n",
    "\n",
    "![](../media/types_of_joins.jpg)\n",
    "\n",
    "*Fig. 1 - Types of joins in SQL, note how left, right, outer and inner translate directly to Pandas.*\n",
    "\n",
    "A refresher on different types of joins, all supported by Pandas:\n",
    "\n",
    "| Pandas                                         | SQL              | What it does                              |\n",
    "| ---------------------------------------------- | ---------------- | ----------------------------------------- |\n",
    "| `pd.merge(right, left, on='key', how='left')`  | LEFT OUTER JOIN  | Use all keys from left frame only         |\n",
    "| `pd.merge(right, left, on='key', how='right')` | RIGHT OUTER JOIN | Use all keys from right frame only        |\n",
    "| `pd.merge(right, left, on='key', how='outer')` | FULL OUTER JOIN  | Use union of keys from both frames        |\n",
    "| `pd.merge(right, left, on='key', how='inner')` | INNER JOIN       | Use intersection of keys from both frames |\n",
    "\n",
    "In this particular case, we have:\n",
    "* A one-to-many relationship (i.e., one program to many concerts)\n",
    "* Since every single show in `concerts` has a match in `programs`, the type of join we use doesn't matter.\n",
    "\n",
    "We can use the `validate` argument to automatically check whether there are unexpected duplicates in the merge keys and check their uniqueness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df__ = pd.merge(programs, concerts, on='GUID', how='outer', validate=\"one_to_many\")\n",
    "assert(concerts.shape[0] == df_.shape[0] == df__.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to our question, how is the number of concerts per season evolving?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(programs.merge(concerts, on='GUID')\n",
    "         .groupby('Season')\n",
    "         .size()\n",
    "         .plot(legend=False, use_index=True, figsize=(10, 7),\n",
    "               title='Number of concerts per season (from 1842-43 to 2016-17)'));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, the number of concerts seems to be trending upwards since about 1995, which could be a sign of growing interest in the genre.\n",
    "\n",
    "### Join\n",
    "\n",
    "Now, we want the top-3 composer in total appearances.\n",
    "\n",
    "Without surprise, we start by importing `works.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "works = pd.read_csv('./data/works.csv',index_col='GUID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can use `df.join()` instead of `df.merge()`. \n",
    "\n",
    "There are, however, differences in the default behavior: for example `df.join` uses `how='left'` by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to perform the merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(programs.merge(works, on=\"GUID\")\n",
    "         .head(n=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "programs.merge(works, on=\"GUID\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(programs.join(works, on='GUID')\n",
    "         .head(n=3))\n",
    "\n",
    "# equivalent to\n",
    "# pd.merge(programs, works, left_on='GUID', right_index=True,\n",
    "#          how='left').head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "programs.join(works, on=\"GUID\").shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noticed that the shape of the results is diferent, we have a different number of lines in each one of the methods.\n",
    "Typically, you would use `df.join()` when you want to do a left join or when you want to join on the index of the dataframe on the right.\n",
    "\n",
    "Now for our goal: what are the top-3 composers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(programs.join(works, on='GUID')\n",
    "         .groupby('ComposerName')\n",
    "         .size()\n",
    "         .nlargest(n=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wagner wins!\n",
    "\n",
    "What about the top-3 works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(programs.join(works, on='GUID')\n",
    "         .groupby(['ComposerName', 'WorkTitle'])\n",
    "         .size()\n",
    "         .nlargest(n=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wagner wins three times!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
