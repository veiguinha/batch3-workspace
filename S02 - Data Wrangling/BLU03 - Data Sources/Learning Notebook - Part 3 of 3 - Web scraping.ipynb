{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLU03 - Learning Notebook - Part 3 of 3 - Web scraping\n",
    "\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "In the context of data wrangling, we've already talked about three data sources: files, databases and public APIs.\n",
    "Now it's time to delve into the Web!\n",
    "\n",
    "As we all know, there is a huge amount of data in the Web. Whenever we search something on Google, it shows us thousands of web pages full of answers.\n",
    "\n",
    "However, there is a problem here: in most of the cases, the web pages show us the data in a beautiful but unstructured way. This makes sense, since the purpose of a web page is to be read by a human and not to have its content analysed by some computer program.\n",
    "\n",
    "So we are left with the boring task of copying and pasting the data we want into csv files or excel tables, possibly thousands of times, before feeding it to some data model...\n",
    "\n",
    "But worry no more!\n",
    "\n",
    "<img src=\"media/web_scraping_to_the_rescue.png\" width=350/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. What is web scraping\n",
    "\n",
    "[Web scraping](https://en.wikipedia.org/wiki/Web_scraping) is the name given to the process of extracting data from web pages in an automated way.\n",
    "There are many [techniques](https://en.wikipedia.org/wiki/Web_scraping#Techniques) that can be used to do web scraping and the one we're going to explore here is HTML parsing.\n",
    "\n",
    "A web page is an HTML document, so HTML parsing means to split the contents of a web page into several small pieces and select the parts we find interesting. This technique is usefull when we want to extract data from many web pages that share a common template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Understanding the HTML code of a web page\n",
    "\n",
    "Before jumping to the part where we actually do web scraping, let's first understand the structure and code of a web page.\n",
    "\n",
    "Usually, a web page has 3 different types of code:\n",
    "* **HTML**: used to display the content of the web page\n",
    "* **CSS**: used to apply styles to the web page, it's what makes the page pretty\n",
    "* **JavaScript**: this is what makes the page dynamic, like triggering an action when a button is clicked.\n",
    "\n",
    "We'll focus now on the HTML part, since it's the one that concerns what we want, which is data.\n",
    "\n",
    "In file **../web_pages/nationalmuseum.html** you can see an example of an HTML document that represents a web page. Let's see the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html>\n",
      "  <body>\n",
      "    <h1>Webpage about the Nationamuseum</h1>\n",
      "    <h3>It's in Sweden.</h3>\n",
      "    <p>For more informations:</p>\n",
      "    <br>\n",
      "    <p>Check wikipedia!</p>\n",
      "  </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "# use ! type for Windows (use full path)\n",
    "# ! cat web_pages/nationalmuseum.html\n",
    "# C:\\Users\\caixi\\OneDrive\\Documents\\GitHub\\batch3-workspace\\S02 - Data Wrangling\\BLU03 - Data Sources\\web_pages\n",
    "! type web_pages\\nationalmuseum.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is how the page looks in a browser.\n",
    "\n",
    "![title](media/nationalmuseum_page_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, an HTML page is a collection of HTML elements, where an element has the form:\n",
    "```<tagname> content </tagname>```.\n",
    "\n",
    "HTML elements can be nested with other HTML elements, meaning that the content between the start and end tags can be a set of elements.\n",
    "\n",
    "An HTML element can also have no content. In that case, it's simply a tagname, like this:\n",
    "```<tagname>```.\n",
    "\n",
    "Let's go through the elements in this page:\n",
    "- the ```<!DOCTYPE html>``` says that this document is an HTML document\n",
    "- the ```<html>``` element is the root element of an HTML page\n",
    "- the ```<body>``` element has the page content\n",
    "- the ```<h1>``` element is a large heading\n",
    "- the ```<h3>``` element is a smaller heading\n",
    "- the ```<p>``` element is a paragraph\n",
    "- the ```<br>``` element is a line break, which is an example of an element without content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. How to web scrape\n",
    "\n",
    "Now let's go to the fun part!\n",
    "\n",
    "Going back to our movies database, you can see that there are some characers for which we're missing the character_name.\n",
    "You can try to query the database to find which are these characters, but in the meanwhile, we gathered them in file **../data/missing_character_names.csv**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "# Import some helper functions to print shorter outputs\n",
    "import utils\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>actor_id</th>\n",
       "      <th>name</th>\n",
       "      <th>character_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1073</td>\n",
       "      <td>718</td>\n",
       "      <td>tt0116405</td>\n",
       "      <td>82957</td>\n",
       "      <td>Dan Aykroyd</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1218</td>\n",
       "      <td>17579</td>\n",
       "      <td>tt0120240</td>\n",
       "      <td>105261</td>\n",
       "      <td>Bonnie Hunt</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1219</td>\n",
       "      <td>17579</td>\n",
       "      <td>tt0120240</td>\n",
       "      <td>79974</td>\n",
       "      <td>N'Bushe Wright</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1220</td>\n",
       "      <td>17579</td>\n",
       "      <td>tt0120240</td>\n",
       "      <td>55658</td>\n",
       "      <td>Michael Rapaport</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1221</td>\n",
       "      <td>17579</td>\n",
       "      <td>tt0120240</td>\n",
       "      <td>57737</td>\n",
       "      <td>Denis Leary</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  movie_id     imdb_id  actor_id              name  character_name\n",
       "0  1073       718  tt0116405      82957       Dan Aykroyd             NaN\n",
       "1  1218     17579  tt0120240     105261       Bonnie Hunt             NaN\n",
       "2  1219     17579  tt0120240      79974    N'Bushe Wright             NaN\n",
       "3  1220     17579  tt0120240      55658  Michael Rapaport             NaN\n",
       "4  1221     17579  tt0120240      57737       Denis Leary             NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_character_names = pd.read_csv('data/missing_character_names.csv')\n",
    "missing_character_names.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you think of a good way to get this missing data? [IMDb](https://www.imdb.com) seems a very good candidate!\n",
    "\n",
    "The first thing to do is to open the web page that has the content we're interested in. The URLs of movie pages in IMDb follow a standard: they all start with https://www.imdb.com/title/ followed by the IMDB movie id.\n",
    "\n",
    "For instance, for the first movie with a missing character name, we can get the correspondent page using the URL https://www.imdb.com/title/tt0116405/. This is the page.\n",
    "\n",
    "<img src=\"media/imdb_movie_page.png\"/>\n",
    "\n",
    "Now, let's head to the cast section of the page, since this is what we'll be scraping.\n",
    "\n",
    "<img src=\"media/imdb_cast.png\"/>\n",
    "\n",
    "In order to get the page's content, we'll use a GET request.\n",
    "\n",
    "Then, we can get the content from the response, which will be... a bunch of incomprehensible HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\n\\n\\n\\n\\n\\n\\n<!DOCTYPE html>\\n<html\\n    xmlns:og=\"http://ogp.me/ns#\"\\n    xmlns:fb=\"http://www.facebook.com/2008/fbml\">\\n    <head>\\n         \\n        <meta charset=\"utf-8\">\\n        <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\\n\\n    <meta name=\"apple-itunes-app\" content=\"app-id=342792525, app-argument=imdb:///title/tt0116405?src=mdot\">\\n\\n\\n\\n        <script type=\"text/javascript\">var IMDbTimer={starttime: new Date().getTime(),pt:\\'java\\'};</script>\\n\\n<script>\\n    if (typeof uet == \\'function\\') {\\n      ue'\n"
     ]
    }
   ],
   "source": [
    "response = requests.get('https://www.imdb.com/title/tt0116405/')\n",
    "# Printing short output, if you want to see everything, delete the friendly_print function call\n",
    "utils.friendly_print_string(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is where **Beautiful Soup** can help us. Beautiful soup is a package for parsing HTML documents, you can check its documentation [here](https://www.crummy.com/software/BeautifulSoup/bs4/doc/).\n",
    "\n",
    "First, we need to create an instance of the BeautifulSoup class, passing it the HTML document to parse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By calling the **prettify** method, we can see the HTML elements of the document in a pretty and indented way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html xmlns:fb=\"http://www.facebook.com/2008/fbml\" xmlns:og=\"http://ogp.me/ns#\">\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n",
      "  <meta content=\"app-id=342792525, app-argument=imdb:///title/tt0116405?src=mdot\" name=\"apple-itunes-app\"/>\n",
      "  <script type=\"text/javascript\">\n",
      "   var IMDbTimer={starttime: new Date().getTime(),pt:'java'};\n",
      "  </script>\n",
      "  <script>\n",
      "   if (typeof uet == 'function') {\n",
      "      uet(\"bb\", \"LoadTitle\", {wb: 1});\n",
      "    }\n",
      "  </s\n"
     ]
    }
   ],
   "source": [
    "# Printing short output, if you want to see everything, delete the friendly_print function call\n",
    "utils.friendly_print_string(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By calling the **children** property of the soup, we can parse it into smaller elements. The idea is that an HTML element will correspond to a beautiful soup element.\n",
    "Let's see an example.\n",
    "\n",
    "This soup has 5 elements:\n",
    "* 3 NavigableString elements, with a single \\n\n",
    "* a Doctype element, with the value 'html'\n",
    "* a Tag element, with tag html\n",
    "\n",
    "We're particularly interested in the Tag element, which is where the HTML content is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# inspecting the elements in the soup\n",
    "soup_children = list(soup.children)\n",
    "\n",
    "# uncomment the next line to print the output, we didn't do it here because it's too long :/\n",
    "# soup_children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[bs4.element.NavigableString,\n",
       " bs4.element.Doctype,\n",
       " bs4.element.NavigableString,\n",
       " bs4.element.Tag,\n",
       " bs4.element.NavigableString]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspecting the types of the elements in the soup\n",
    "[type(item) for item in soup_children]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the html tag element from the soup, we can just call it by its name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(soup.html)\n",
    "\n",
    "# uncomment the next line to print the output, we didn't do it here because it's too long :/\n",
    "#soup.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get to an actual content, we can navigate through the tags until we reach a tag that has a value as content (instead of other elements)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Crime com Castigo (1996) - IMDb</title>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.html.head.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, by calling method **get_text**, we can get the content of the element as a string (here it's in Portuguese)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Crime com Castigo (1996) - IMDb'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.html.head.title.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now, you must be thinking that this is somehow a complicated process, as it requires manually inspecting the HTML document and navigating through thousands of tags in order to find the interesting content in the middle of a big mess. And you're right :)\n",
    "\n",
    "You'll now see a very easy way to access the interesting content directly.\n",
    "\n",
    "First, you need to open the developer tools of your browser in the page to scrape.\n",
    "In Google Chrome, you just have to right-click the page and select the \"Inspect\" option. \n",
    "For other browsers, google \"How to open developer tools in *browser name*\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](media/dt_open.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The developer tools will open at the bottom of the window. Now, when you hover something on the page with your mouse, you'll see the correspondent HTML element highlighted in the developer tools window."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](media/dt_actordiv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that all the actor and character names are inside an element with tag **div** and class **article**. The classes inside HTML elements are related to the CSS styles of the web page and not with the content. However, they are useful to identify the elements that we're trying to parse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect even further and notice that one of this element's children has tag **table** and class **cast_list** - we're getting closer! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](media/dt_castlist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can call the soup's **find_all** method to find this table (and make sure there's only one in this page)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements found:  1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<table class=\"cast_list\">\n",
       "<tr><td class=\"castlist_label\" colspan=\"4\">Cast overview, first billed only:</td></tr>\n",
       "<tr class=\"odd\">\n",
       "<td class=\"primary_photo\">\n",
       "<a href=\"/name/nm0000101/\"><img alt=\"Dan Aykroyd\" class=\"loadlate hidden\" height=\"44\" loadlate=\"https://m.media-amazon.com/images/M/MV5BMTI2MDA3NTg0NF5BMl5BanBnXkFtZTYwMzM5ODgz._V1_UX32_CR0,0,32,44_AL_.jpg\" src=\"https://m.media-amazon.com/images/G/01/imdb/images/nopicture/32x44/name-2138558783._CB470041625_.png\" title=\"Dan Aykroyd\" width=\"32\"/></a> </td>\n",
       "<td>\n",
       "<a href=\"/name/nm0000101/\"> Dan Aykroyd\n",
       "</a> </td>\n",
       "<td class=\"ellipsis\">\n",
       "              ...\n",
       "          </td>\n",
       "<td class=\"character\">\n",
       "<a href=\"/title/tt0116405/characters/nm0000101\">Jack Lambert</a>\n",
       "</td>\n",
       "</tr>\n",
       "<tr class=\"even\">\n",
       "<td class=\"primary_photo\">\n",
       "<a href=\"/name/nm0005499/\"><img alt=\"Lily Tomlin\" class=\"loadlate hidden\" height=\"44\" loadlate=\"https://m.media-amazon.com/images/M/MV5BMTYwNjc5NzA2NV5BMl5BanBnXkFtZTcwNjk1MTk3Mw@@._V1_UX32_CR0,0,32,44_AL_.jpg\" src=\"https://m.media-amazon.com/images/G/01/imdb/images/nopicture/32x44/name-2138558783._CB470041625_.png\" title=\"Lily Tomlin\" width=\"32\"/></a> </td>\n",
       "<td>\n",
       "<a href=\"/name/nm0005499/\"> Lily Tomlin\n",
       "</a> </td>\n",
       "<td class=\"ellipsis\">\n",
       "              ...\n",
       "          </td>\n",
       "<td class=\"character\">\n",
       "<a href=\"/title/tt0116405/characters/nm0005499\">Inga Mueller</a>\n",
       "</td>\n",
       "</tr>\n",
       "<tr class=\"odd\">\n",
       "<td class=\"primary_photo\">\n",
       "<a href=\"/name/nm0000493/\"><img alt=\"Jack Lemmon\" class=\"loadlate hidden\" height=\"44\" loadlate=\"https://m.media-amazon.com/images/M/MV5BMTE5NTE3ODE1N15BMl5BanBnXkFtZTYwOTU1MTM2._V1_UX32_CR0,0,32,44_AL_.jpg\" src=\"https://m.media-amazon.com/images/G/01/imdb/images/nopicture/32x44/name-2138558783._CB470041625_.png\" title=\"Jack Lemmon\" width=\"32\"/></a> </td>\n",
       "<td>\n",
       "<a href=\"/name/nm0000493/\"> Jack Lemmon\n",
       "</a> </td>\n",
       "<td class=\"ellipsis\">\n",
       "              ...\n",
       "          </td>\n",
       "<td class=\"character\">\n",
       "<a href=\"/title/tt0116405/characters/nm0000493\">Max Mueller</a> /  \n",
       "            <a href=\"/title/tt0116405/characters/nm0000493\">Karl Luger</a>\n",
       "</td>\n",
       "</tr>\n",
       "<tr class=\"even\">\n",
       "<td class=\"primary_photo\">\n",
       "<a href=\"/name/nm0001372/\"><img alt=\"Bonnie Hunt\" class=\"loadlate hidden\" height=\"44\" loadlate=\"https://m.media-amazon.com/images/M/MV5BMDMwZDJmMzMtNGYxZi00OTY2LWJhMmEtNDI5MzBmMjJlOGExXkEyXkFqcGdeQXVyMjUyNDk2ODc@._V1_UX32_CR0,0,32,44_AL_.jpg\" src=\"https://m.media-amazon.com/images/G/01/imdb/images/nopicture/32x44/name-2138558783._CB470041625_.png\" title=\"Bonnie Hunt\" width=\"32\"/></a> </td>\n",
       "<td>\n",
       "<a href=\"/name/nm0001372/\"> Bonnie Hunt\n",
       "</a> </td>\n",
       "<td class=\"ellipsis\">\n",
       "              ...\n",
       "          </td>\n",
       "<td class=\"character\">\n",
       "<a href=\"/title/tt0116405/characters/nm0001372\">Dr. Gail Holland</a>\n",
       "</td>\n",
       "</tr>\n",
       "<tr class=\"odd\">\n",
       "<td class=\"primary_photo\">\n",
       "<a href=\"/name/nm0450116/\"><img alt=\"Brian Kerwin\" class=\"loadlate hidden\" height=\"44\" loadlate=\"https://m.media-amazon.com/images/M/MV5BNWY0ZDFhMDEtZjQ1Yy00ZjRhLTlhNjktYzQ5MDY5MTllMGRiXkEyXkFqcGdeQXVyMTYwMzE2OTE@._V1_UX32_CR0,0,32,44_AL_.jpg\" src=\"https://m.media-amazon.com/images/G/01/imdb/images/nopicture/32x44/name-2138558783._CB470041625_.png\" title=\"Brian Kerwin\" width=\"32\"/></a> </td>\n",
       "<td>\n",
       "<a href=\"/name/nm0450116/\"> Brian Kerwin\n",
       "</a> </td>\n",
       "<td class=\"ellipsis\">\n",
       "              ...\n",
       "          </td>\n",
       "<td class=\"character\">\n",
       "            Marty Lambert \n",
       "                  \n",
       "          </td>\n",
       "</tr>\n",
       "<tr class=\"even\">\n",
       "<td class=\"primary_photo\">\n",
       "<a href=\"/name/nm0012178/\"><img alt=\"Jerry Adler\" class=\"loadlate hidden\" height=\"44\" loadlate=\"https://m.media-amazon.com/images/M/MV5BMTQ0OTU5ODYxMF5BMl5BanBnXkFtZTcwNjYxNzM3Mw@@._V1_UX32_CR0,0,32,44_AL_.jpg\" src=\"https://m.media-amazon.com/images/G/01/imdb/images/nopicture/32x44/name-2138558783._CB470041625_.png\" title=\"Jerry Adler\" width=\"32\"/></a> </td>\n",
       "<td>\n",
       "<a href=\"/name/nm0012178/\"> Jerry Adler\n",
       "</a> </td>\n",
       "<td class=\"ellipsis\">\n",
       "              ...\n",
       "          </td>\n",
       "<td class=\"character\">\n",
       "            Judge \n",
       "                  \n",
       "          </td>\n",
       "</tr>\n",
       "<tr class=\"odd\">\n",
       "<td class=\"primary_photo\">\n",
       "<a href=\"/name/nm0738850/\"><img alt=\"Andy Romano\" class=\"loadlate hidden\" height=\"44\" loadlate=\"https://m.media-amazon.com/images/M/MV5BZjU3MTliODItOGM0OS00NTVjLWE4MTktMmIyNjRiYTM5MWFiXkEyXkFqcGdeQXVyMjUyNDk2ODc@._V1_UY44_CR23,0,32,44_AL_.jpg\" src=\"https://m.media-amazon.com/images/G/01/imdb/images/nopicture/32x44/name-2138558783._CB470041625_.png\" title=\"Andy Romano\" width=\"32\"/></a> </td>\n",
       "<td>\n",
       "<a href=\"/name/nm0738850/\"> Andy Romano\n",
       "</a> </td>\n",
       "<td class=\"ellipsis\">\n",
       "              ...\n",
       "          </td>\n",
       "<td class=\"character\">\n",
       "<a href=\"/title/tt0116405/characters/nm0738850\">Psychiatrist</a>\n",
       "</td>\n",
       "</tr>\n",
       "<tr class=\"even\">\n",
       "<td class=\"primary_photo\">\n",
       "<a href=\"/name/nm0276341/\"><img alt=\"Robert Fields\" class=\"\" height=\"44\" src=\"https://m.media-amazon.com/images/G/01/imdb/images/nopicture/32x44/name-2138558783._CB470041625_.png\" title=\"Robert Fields\" width=\"32\"/></a> </td>\n",
       "<td>\n",
       "<a href=\"/name/nm0276341/\"> Robert Fields\n",
       "</a> </td>\n",
       "<td class=\"ellipsis\">\n",
       "              ...\n",
       "          </td>\n",
       "<td class=\"character\">\n",
       "            Sergeant Roarke \n",
       "                  \n",
       "          </td>\n",
       "</tr>\n",
       "<tr class=\"odd\">\n",
       "<td class=\"primary_photo\">\n",
       "<a href=\"/name/nm0703862/\"><img alt=\"J.C. Quinn\" class=\"loadlate hidden\" height=\"44\" loadlate=\"https://m.media-amazon.com/images/M/MV5BODMyNzUwNDgtY2U4ZS00ZTgyLTkzNjMtNGFmY2Y3ZTc5NjdmXkEyXkFqcGdeQXVyNTIzOTk5ODM@._V1_UY44_CR18,0,32,44_AL_.jpg\" src=\"https://m.media-amazon.com/images/G/01/imdb/images/nopicture/32x44/name-2138558783._CB470041625_.png\" title=\"J.C. Quinn\" width=\"32\"/></a> </td>\n",
       "<td>\n",
       "<a href=\"/name/nm0703862/\"> J.C. Quinn\n",
       "</a> </td>\n",
       "<td class=\"ellipsis\">\n",
       "              ...\n",
       "          </td>\n",
       "<td class=\"character\">\n",
       "            Detective Stanley \n",
       "                  \n",
       "          </td>\n",
       "</tr>\n",
       "<tr class=\"even\">\n",
       "<td class=\"primary_photo\">\n",
       "<a href=\"/name/nm0286759/\"><img alt=\"Susan Forristal\" class=\"\" height=\"44\" src=\"https://m.media-amazon.com/images/G/01/imdb/images/nopicture/32x44/name-2138558783._CB470041625_.png\" title=\"Susan Forristal\" width=\"32\"/></a> </td>\n",
       "<td>\n",
       "<a href=\"/name/nm0286759/\"> Susan Forristal\n",
       "</a> </td>\n",
       "<td class=\"ellipsis\">\n",
       "              ...\n",
       "          </td>\n",
       "<td class=\"character\">\n",
       "            Waitress Patti \n",
       "                  \n",
       "          </td>\n",
       "</tr>\n",
       "<tr class=\"odd\">\n",
       "<td class=\"primary_photo\">\n",
       "<a href=\"/name/nm0157149/\"><img alt=\"Marissa Chibas\" class=\"\" height=\"44\" src=\"https://m.media-amazon.com/images/G/01/imdb/images/nopicture/32x44/name-2138558783._CB470041625_.png\" title=\"Marissa Chibas\" width=\"32\"/></a> </td>\n",
       "<td>\n",
       "<a href=\"/name/nm0157149/\"> Marissa Chibas\n",
       "</a> </td>\n",
       "<td class=\"ellipsis\">\n",
       "              ...\n",
       "          </td>\n",
       "<td class=\"character\">\n",
       "            Liz Lambert \n",
       "                  \n",
       "          </td>\n",
       "</tr>\n",
       "<tr class=\"even\">\n",
       "<td class=\"primary_photo\">\n",
       "<a href=\"/name/nm0466300/\"><img alt=\"Jon Korkes\" class=\"loadlate hidden\" height=\"44\" loadlate=\"https://m.media-amazon.com/images/M/MV5BMmE3MDI1NjYtMDIxYy00ZjhjLTk3NTMtYzZjMGIyMzgzMGY4XkEyXkFqcGdeQXVyMjUyNDk2ODc@._V1_UY44_CR23,0,32,44_AL_.jpg\" src=\"https://m.media-amazon.com/images/G/01/imdb/images/nopicture/32x44/name-2138558783._CB470041625_.png\" title=\"Jon Korkes\" width=\"32\"/></a> </td>\n",
       "<td>\n",
       "<a href=\"/name/nm0466300/\"> Jon Korkes\n",
       "</a> </td>\n",
       "<td class=\"ellipsis\">\n",
       "              ...\n",
       "          </td>\n",
       "<td class=\"character\">\n",
       "            Chemistry Lab Professor \n",
       "                  \n",
       "          </td>\n",
       "</tr>\n",
       "<tr class=\"odd\">\n",
       "<td class=\"primary_photo\">\n",
       "<a href=\"/name/nm0550982/\"><img alt=\"Kathleen Marshall\" class=\"loadlate hidden\" height=\"44\" loadlate=\"https://m.media-amazon.com/images/M/MV5BMTQwMzUyMDg1OF5BMl5BanBnXkFtZTYwODE2OTk2._V1_UY44_CR10,0,32,44_AL_.jpg\" src=\"https://m.media-amazon.com/images/G/01/imdb/images/nopicture/32x44/name-2138558783._CB470041625_.png\" title=\"Kathleen Marshall\" width=\"32\"/></a> </td>\n",
       "<td>\n",
       "<a href=\"/name/nm0550982/\"> Kathleen Marshall\n",
       "</a> </td>\n",
       "<td class=\"ellipsis\">\n",
       "              ...\n",
       "          </td>\n",
       "<td class=\"character\">\n",
       "            Student #1 \n",
       "                  \n",
       "          </td>\n",
       "</tr>\n",
       "<tr class=\"even\">\n",
       "<td class=\"primary_photo\">\n",
       "<a href=\"/name/nm0458792/\"><img alt=\"Jacqueline Klein\" class=\"loadlate hidden\" height=\"44\" loadlate=\"https://m.media-amazon.com/images/M/MV5BN2U4YWQ0OTctNjlkMS00ODI3LTkzNzktZDMyM2VhMzRjYjAxXkEyXkFqcGdeQXVyODU4MTQ5NjA@._V1_UX32_CR0,0,32,44_AL_.jpg\" src=\"https://m.media-amazon.com/images/G/01/imdb/images/nopicture/32x44/name-2138558783._CB470041625_.png\" title=\"Jacqueline Klein\" width=\"32\"/></a> </td>\n",
       "<td>\n",
       "<a href=\"/name/nm0458792/\"> Jacqueline Klein\n",
       "</a> </td>\n",
       "<td class=\"ellipsis\">\n",
       "              ...\n",
       "          </td>\n",
       "<td class=\"character\">\n",
       "            Student #2 \n",
       "                  \n",
       "          </td>\n",
       "</tr>\n",
       "<tr class=\"odd\">\n",
       "<td class=\"primary_photo\">\n",
       "<a href=\"/name/nm0032185/\"><img alt=\"Alex Appel\" class=\"loadlate hidden\" height=\"44\" loadlate=\"https://m.media-amazon.com/images/M/MV5BYmYxYzdhODMtZDU0Yi00NjUwLWE5MGMtZmU0MzEzMGI5ZmI1XkEyXkFqcGdeQXVyMjQwMDg0Ng@@._V1_UY44_CR17,0,32,44_AL_.jpg\" src=\"https://m.media-amazon.com/images/G/01/imdb/images/nopicture/32x44/name-2138558783._CB470041625_.png\" title=\"Alex Appel\" width=\"32\"/></a> </td>\n",
       "<td>\n",
       "<a href=\"/name/nm0032185/\"> Alex Appel\n",
       "</a> </td>\n",
       "<td class=\"ellipsis\">\n",
       "              ...\n",
       "          </td>\n",
       "<td class=\"character\">\n",
       "            Student #3 \n",
       "                  \n",
       "          </td>\n",
       "</tr>\n",
       "</table>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cast_list = soup.find_all('table', class_=\"cast_list\")\n",
    "print(\"Number of elements found: \", len(cast_list))\n",
    "\n",
    "cast_table = cast_list[0]\n",
    "cast_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! Now we still need to clean up a bit more. Inside the table, we have several elements, but the ones that interest us are the ones with the **td** tag. By inspection, we can see that the actor names are inside the **td** elements that *don't* have a class!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](media/dt_select_actor.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select these elements in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_tags = cast_table.find_all('td', class_=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, by calling the get_text method in each td element, we get the actor names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dan Aykroyd', 'Lily Tomlin', 'Jack Lemmon']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actor_names = [actor.get_text().strip() for actor in actor_tags]\n",
    "actor_names[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see another example, where we get the character names.\n",
    "\n",
    "We need to open the developer tools again and inspect the element that contains the character name.\n",
    "\n",
    "![title](media/dt_select_character.png)\n",
    "\n",
    "This time it's simpler. We need to find td tags with character class, and get their content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jack Lambert', 'Inga Mueller', 'Max Mueller / Karl Luger']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "character_names = [c.get_text() for c in cast_table.find_all('td', class_='character')]\n",
    "\n",
    "# this is to strip the \\n and blank spaces in the strings\n",
    "character_names = [' '.join(c.split()) for c in character_names]\n",
    "character_names[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we have found Dan Aykroyd's character in movie tt0116405, which is Jack Lambert!\n",
    "\n",
    "And the best part is that it will only take some minutes to get all the other missing character names. You're invited to do that as an exercise :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Optional\n",
    "\n",
    "### 5.1 Scraping and the Law\n",
    "\n",
    "[This](https://benbernardblog.com/web-scraping-and-crawling-are-perfectly-legal-right/) is an interesting article about the subject, bottom line being: when scraping web pages, don't use a very high request rate, so that the owners of the website don't get angry.\n",
    "\n",
    "### 5.2 Scraping and JavaScript\n",
    "\n",
    "Sometimes, when scraping web pages, you'll need to navigate from one page to the other, click buttons, or take other actions that enter the JavaScript domain. In such cases, Beautiful Soup is not enough to fill your needs. If you find yourself there, take a look at [Selenium](https://www.seleniumhq.org/).\n",
    "\n",
    "### 5.3 Scraping tools\n",
    "\n",
    "If you're really into the world of scraping, you can give [parsehub](https://www.parsehub.com/) or [portia](https://github.com/scrapinghub/portia) a try! For scraping using Python, [scrapy](https://scrapy.org/) is also a good choice."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
